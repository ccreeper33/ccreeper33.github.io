---
title: "MIT 6.5840(6.824) - lab 1: MapReduce"
date: 2024-02-16 21:37:42
tags: 
- åˆ†å¸ƒå¼
- csdiy
categories: å­¦ç‚¹æ–°ä¸œè¥¿
---

è€ƒå®Œç ”æƒ³ç»™è‡ªå·±çš„ç®€å†é•€é‡‘ï¼ˆçŒæ°´ï¼Ÿï¼‰ï¼Œäºæ˜¯æƒ³åšä¸€ä¸‹å¤§åé¼é¼çš„ MIT 6.5840(or 6.824) ã€‚ç†è®ºçŸ¥è¯†å’Œæ¡†æ¶éƒ½åœ¨âš¡ğŸ§±çš„è¯¾ç¨‹ä¸­å­¦ä¹ å’Œä½¿ç”¨è¿‡ï¼Œæ‰€ä»¥å¯¹äº lectures å°±å¿«é€Ÿæµè§ˆäº†[ç¿»è¯‘ç‰ˆæœ¬](https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/)ï¼Œç›´æ¥è¿›å…¥ projects é˜¶æ®µï¼š

<!--more-->

# é˜…è¯»è®ºæ–‡

[MapReduce è®ºæ–‡](http://research.google.com/archive/mapreduce-osdi04.pdf)ä¸­ç»™å‡ºäº†åœ¨ä¸€ä¸ªç”±å¤§é‡æ¶ˆè´¹çº§ PC å’Œç½‘ç»œç»„æˆçš„é›†ç¾¤ä¸Šå®ç° MapReduce çš„æ€è·¯ã€‚ç„¶è€Œ lab 1 ä¸­è¦æ±‚çš„ç¯å¢ƒæ˜¯åœ¨å•æœºä¸Šï¼Œä½¿ç”¨è¿›ç¨‹æ¨¡æ‹Ÿçš„åˆ†å¸ƒå¼ç¯å¢ƒï¼Œæ‰€ä»¥å®Œå…¨ç…§æ¬è®ºæ–‡æ€è·¯ä¼¼ä¹å¹¶ä¸åˆç†ã€‚~ï¼ˆå¦ï¼Œlab 1 ä¸­å°†è®ºæ–‡çš„ master ç§°ä¸º coordinator æ˜¯å¦æœ‰ç‚¹å¤ªè¿‡æ”¿æ²»æ­£ç¡®äº†â€¦â€¦ï¼‰~

## åˆ†ææ‰§è¡Œè¿‡ç¨‹

> We have given you a little code to start you off. The "main" routines for the coordinator and worker are in `main/mrcoordinator.go` and `main/mrworker.go`; don't change these files. You should put your implementation in `mr/coordinator.go`,` mr/worker.go`, and `mr/rpc.go`. 

lab ä¸­ç»™å‡ºäº†åŸºæœ¬çš„æ‰§è¡Œæ¡†æ¶ï¼Œä¸è®ºæ–‡ä¸­çš„ç•¥æœ‰åŒºåˆ«ã€‚æ­£å¦‚è®ºæ–‡ä¸­æåˆ°çš„ï¼Œ

> Many different implementations of the MapReduce interface are possible. The right choice depends on the environment. 

labçš„è¿è¡Œç¯å¢ƒä¸è®ºæ–‡ä¸­å¹¶ä¸ç›¸åŒã€‚éœ€è¦å®ç°çš„å†…å®¹é›†ä¸­åœ¨ `mr/coordinator.go` ` mr/worker.go` `mr/rpc.go`ä¸‰ä¸ªæ–‡ä»¶ä¸­ã€‚

![è®ºæ–‡ä¸­çš„æ‰§è¡Œè¿‡ç¨‹](mapred_paper.png)

### Action 1 å‡†å¤‡å·¥ä½œ

> The MapReduce library in the user program first splits the input files into M pieces of typically 16 megabytes to 64 megabytes (MB) per piece (controllable by the user via an optional parameter). It then starts up many copies of the program on a cluster of machines.

è®ºæ–‡ä¸­çš„ç¬¬ä¸€æ­¥ï¼Œç”±ç”¨æˆ·ç¨‹åºè°ƒç”¨MapReduceåº“ï¼Œå°†è¾“å…¥æ–‡ä»¶åˆ†å‰²ä¸ºMä¸ª16-64MB çš„å—ï¼ˆå¯¹åº”åç»­äº§ç”Ÿçš„Mä¸ªmapä»»åŠ¡ï¼‰ï¼Œç„¶ååœ¨é›†ç¾¤ä¸­forkå‡ºå¤šä»½ç¨‹åºçš„å‰¯æœ¬ï¼Œå…¶ä¸­ä¸€ä¸ªä¸ºMasterï¼Œå…¶ä½™ä¸ºWorkerã€‚

è€Œlabä¸­ï¼Œç”¨æˆ·ç¨‹åºå¯¹åº”äº†`main/mrcoordinator.go`ï¼ˆåˆ›å»ºcoordinatorè¿›ç¨‹ï¼‰`main/mrworker.go`ï¼ˆåˆ›å»ºworkerè¿›ç¨‹ï¼‰`test-mr.sh`ï¼ˆæ‰§è¡Œè„šæœ¬ï¼‰`mrapps/*.go`ï¼ˆå®šä¹‰map/reduceå‡½æ•°ï¼Œä»¥[Go plugin](https://pkg.go.dev/plugin)çš„å½¢å¼åŠ è½½è‡³workerï¼‰ã€‚è¿™ä¸€éƒ¨åˆ†å‡ä¸ºç»™å®šçš„ä»£ç ï¼Œä¸éœ€è¦è‡ªå·±å®ç°ã€‚å¯¹äºæ–‡ä»¶åˆ†å‰²ï¼Œlabä¸­ç»™å‡ºçš„æ–¹æ¡ˆæ˜¯ç›´æ¥æŒ‰ç…§æ–‡ä»¶æ‰§è¡Œmapä»»åŠ¡ï¼Œä¸éœ€è¦åˆ†å‰²ã€‚

### Action 2 è§’è‰²åˆ’åˆ†

> One of the copies of the program is special â€“ the master. The rest are workers that are assigned work by the master. There are M map tasks and R reduce tasks to assign. The master picks idle workers and assigns each one a map task or a reduce task.

è®ºæ–‡ä¸­ï¼Œç”±masteræŒ‡å®šç©ºé—²çš„workeræ¥æ‰§è¡Œä»»åŠ¡ã€‚è€Œlabä¸­ï¼Œç”±workerï¼ˆé€šè¿‡RPCï¼‰å‘coordinatorè¯·æ±‚ä»»åŠ¡å¹¶æ‰§è¡Œã€‚

### Action 3 - 4 mapä»»åŠ¡é˜¶æ®µ

> A worker who is assigned a map task reads the contents of the corresponding input split. It parses key/value pairs out of the input data and passes each
> pair to the user-defined Map function. The intermediate key/value pairs produced by the Map function are buffered in memory. 

> Periodically, the buffered pairs are written to local disk, partitioned into R regions by the partitioning function. The locations of these buffered pairs on
> the local disk are passed back to the master, who is responsible for forwarding these locations to the reduce workers.

è¿™ä¸€æ­¥ä¸­map workerè¯»å…¥è¾“å…¥æ–‡ä»¶ï¼Œæ‰§è¡Œmapå‡½æ•°ï¼Œå¹¶ç»™å‡ºä¸­é—´æ•°æ®ã€‚

è®ºæ–‡ä¸­ï¼Œè¾“å…¥è¾“å‡ºæ•°æ®ä¿å­˜åœ¨` a global file system`ï¼Œæˆ–è€…åœ¨è¿™ä¸ªç¯å¢ƒä¸‹åº”å½“ç‰¹æŒ‡GFSã€‚ç±»ä¼¼åœ°ï¼Œhadoopå°†MapReduceçš„è¾“å…¥è¾“å‡ºæ•°æ®å­˜æ”¾åœ¨HDFSä¸­ã€‚

è€Œmap workeräº§ç”Ÿçš„ä¸­é—´æ•°æ®å­˜æ”¾åœ¨map workerçš„å†…å­˜ï¼Œå†å®šæœŸåœ°å°†å…¶åˆ†ä¸ºRä»½ï¼ˆå¯¹åº”reduceä»»åŠ¡æ•°é‡ï¼‰ä¿å­˜åœ¨æœ¬åœ°ç¡¬ç›˜ã€‚ç„¶åå°†ä¸­é—´æ•°æ®çš„ä½ç½®è¿”å›è‡³masterï¼Œå¹¶è¿›ä¸€æ­¥ç”±masteré€šçŸ¥reduce workeråº”è¯¥ä»å“ªé‡Œè·å–æ•°æ®ã€‚

å¯¹äºlabï¼Œè¿™éƒ¨åˆ†æ­£æ˜¯éœ€è¦å®ç°çš„ã€‚è€ƒè™‘labçš„å•æœºç¯å¢ƒåŠè¾ƒå°çš„æ•°æ®è§„æ¨¡ï¼Œæ¯”èµ·å®é™…çš„é›†ç¾¤åº”å½“æ›´å®¹æ˜“å®ç°ã€‚

### Action 5 - 6 reduceä»»åŠ¡é˜¶æ®µ

> When a reduce worker is notified by the master about these locations, it uses remote procedure calls to read the buffered data from the local disks of the map workers. When a reduce worker has read all intermediate data, it sorts it by the intermediate keys so that all occurrences of the same key are grouped together. The sorting is needed because typically many different keys map to the same reduce task. If the amount of intermediate data is too large to fit in memory, an external sort is used. 

> The reduce worker iterates over the sorted intermediate data and for each unique intermediate key encountered, it passes the key and the corresponding
> set of intermediate values to the userâ€™s Reduce function. The output of the Reduce function is appended to a final output file for this reduce partition.

è¿™ä¸€æ­¥ä¸­ï¼Œreduce workerè¯»å–ä¸­é—´æ•°æ®ï¼Œæ‰§è¡Œreduceå‡½æ•°ï¼Œå¹¶å¾—å‡ºæœ€ç»ˆçš„è¾“å‡ºæ–‡ä»¶ã€‚åŒæ ·çš„ï¼Œè¿™ä¸€éƒ¨åˆ†æ˜¯éœ€è¦å®ç°çš„ã€‚

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè®ºæ–‡æåˆ°äº†è¶…å‡ºå†…å­˜èŒƒå›´æ—¶ï¼Œéœ€è¦ä½¿ç”¨å¤–éƒ¨æ’åºï¼Œä½†æ˜¯ç»™å‡ºçš„æ ·ä¾‹ç¨‹åº`main/mrsequential.go`å¹¶æ²¡æœ‰å®ç°è¶…å‡ºå†…å­˜èŒƒå›´çš„å¤„ç†æ–¹å¼ï¼Œå®Œå…¨è¿è¡Œäºå†…å­˜ä¸­ã€‚ æ•…åº”å½“ä¸ç”¨è€ƒè™‘è¶…å‡ºå†…å­˜èŒƒå›´çš„æ•°æ®ï¼ˆæ­£å¦‚ä¸Šæ–‡ï¼Œlabçš„æ•°æ®è§„æ¨¡è¿˜æ˜¯æ¯”è¾ƒå‹å¥½çš„ï¼‰ã€‚

### Action 7

> When all map tasks and reduce tasks have been completed, the master wakes up the user program. At this point, the MapReduce call in the user program returns back to the user code.

è®ºæ–‡ä¸­ï¼Œæ‰§è¡Œå®ŒMapReduceè°ƒç”¨åï¼Œå†æ¬¡è¿”å›ç”¨æˆ·ç¨‹åºï¼›è€Œlabä¸­ä¸å­˜åœ¨ç”¨æˆ·ç¨‹åºã€‚

## å®¹é”™

è®ºæ–‡ä¸­æåˆ°äº†ä¸‰ç±»å®¹é”™ï¼š

### workeræ•…éšœ

è®ºæ–‡ä¸­ï¼Œmasteré€šè¿‡å®šæœŸpingæ¥ç¡®è®¤workerå­˜æ´»çŠ¶æ€ã€‚å¦‚æœè¶…æ—¶æœªå“åº”åˆ™è§†ä¸ºworkerå¤±æ•ˆã€‚

| ä»»åŠ¡è¿›åº¦\å¤±æ•ˆç±»å‹ | map worker å¤±æ•ˆ | reduce worker å¤±æ•ˆ |
| :--: | :--: | :--: |
| å·²å®Œæˆ | å¯¹åº”ä»»åŠ¡é‡æ–°æ‰§è¡Œ | æ— éœ€é‡æ–°æ‰§è¡Œ |
| å¤„ç†ä¸­ | å¯¹åº”ä»»åŠ¡é‡æ–°æ‰§è¡Œ | å¯¹åº”ä»»åŠ¡é‡æ–°æ‰§è¡Œ |

æ­£å¦‚ä¸Šæ–‡æåˆ°çš„ï¼Œmap/reduce workeräº§ç”Ÿçš„æ•°æ®å­˜æ”¾äºä¸åŒä½ç½®ã€‚æ‰€ä»¥å¯¹äºå·²å®Œæˆçš„ä»»åŠ¡ï¼Œå¦‚æœæ˜¯mapä»»åŠ¡ï¼Œéœ€è¦é‡æ–°æ‰§è¡Œï¼ˆå› ä¸ºäº§ç”Ÿçš„æ•°æ®å­˜å‚¨åœ¨workeræœ¬åœ°ç£ç›˜ï¼‰ï¼›è€Œå¯¹äºreduceäººç‰©ï¼Œåˆ™æ— éœ€é‡æ–°æ‰§è¡Œï¼ˆå…¶æ•°æ®å­˜å‚¨ä»¥åˆ†å¸ƒå¼å¤šå‰¯æœ¬çš„å½¢å¼å­˜å‚¨äºé›†ç¾¤ä¸­ã€‚

å¯¹äºlabï¼Œå–å†³äºå®ç°æ–¹å¼ï¼Œéœ€è¦ä»¥ä¸åŒæ–¹å¼å¤„ç†workeræ•…éšœï¼šå¦‚æœä¸è®ºæ–‡ä¸€æ ·ï¼Œä¸­é—´æ•°æ®å­˜äºç¡¬ç›˜ï¼Œåˆ™**ä¸**éœ€è¦é‡æ–°æ‰§è¡Œå·²å®Œæˆçš„mapä»»åŠ¡ï¼ˆæ˜¾ç„¶ï¼Œåœ¨å•æœºç¯å¢ƒä¸‹ä¸ç”¨æ‹…å¿ƒworkerå¤±æ•ˆåä¸¢å¤±ä¸­é—´æ–‡ä»¶ï¼‰ï¼›å¦‚æœä¸­é—´æ•°æ®å­˜äºå†…å­˜ï¼Œåˆ™éœ€è¦é‡æ–°æ‰§è¡Œã€‚

åŒæ—¶ï¼Œlabä¸­å¯¹äºåˆ¤æ–­workerå¤±æ•ˆæœ‰ç€ä¸åŒçš„æ–¹å¼ã€‚

> The coordinator should notice if a worker hasn't completed its task in a reasonable amount of time (for this lab, use ten seconds), and give the same task to a different worker.

ä¸åŒäºè®ºæ–‡çš„pingï¼Œlabä½¿ç”¨å®Œæˆæ—¶é—´åˆ¤æ–­workerçŠ¶æ€ï¼ˆå…·ä½“åˆ¤æ–­æ–¹æ³•æœ‰å¾…å®ç°ï¼‰ï¼ˆæ˜¾ç„¶ä¸èƒ½æ˜¯pingï¼‰ã€‚

### master æ•…éšœ

è®ºæ–‡ä¸­æåˆ°ï¼Œå¯ä»¥é€šè¿‡å®šæœŸä¿å­˜masterçŠ¶æ€çš„checkpointæ¥é‡å»ºå¤±æ•ˆçš„masterï¼Œä½†æ˜¯å¯¹äºåªæœ‰ä¸€å°çš„masteråº”å½“ä¸å®¹æ˜“å¤±æ•ˆï¼Œæ‰€ä»¥è®ºæ–‡ä¸è€ƒè™‘masterçš„å®¹é”™ã€‚

è€Œlabæ•´ä½“éƒ½æ˜¯è¿è¡Œäºå•æœºçš„ï¼Œäº‹å®ä¸Šä¸éœ€è¦è€ƒè™‘å®¹é”™ï¼ˆä¸Šæ–‡ä¸­çš„workeræ•…éšœä¸ºé¢˜ç›®è¦æ±‚çš„åˆ¤æ–­æ–¹å¼ï¼‰ã€‚

### Semantics in the Presence of Failures

å³å¯¹äºå…·æœ‰ç¡®å®šæ€§çš„Mapå’ŒReduceæ“ä½œï¼ŒMapReduceæ‰§è¡Œçš„ç»“æœåº”å½“ä¸é¡ºåºæ‰§è¡Œçš„ç»“æœç›¸åŒï¼›è€Œå¯¹äºä¸å…·ç¡®å®šæ€§çš„æ“ä½œï¼ŒMapReduceåº”å½“**ç­‰ä»·äº**ï¼ˆä½†ä¸ä¸€å®šç›¸åŒï¼‰é¡ºåºæ‰§è¡Œï¼ˆè€ƒè™‘ç”Ÿæˆéšæœºæ•°çš„æ“ä½œï¼Œæ˜¾ç„¶è¯­ä¹‰ä¸Šç›¸åŒçš„æ‰§è¡Œå¹¶ä¸ä¸€å®šå¾—åˆ°ç›¸åŒç»“æœï¼‰ã€‚è¿™æ˜¯ç”±MapReduceçš„æ‰§è¡Œè¿‡ç¨‹å†³å®šçš„ã€‚

# å®ç°è¿‡ç¨‹

## æ•°æ®ç±»å‹å®šä¹‰

 é¦–å…ˆåº”å½“æ˜ç¡®ï¼Œè¦å®ç°ä¸€ä¸ªMapReduceæ¡†æ¶ï¼Œéœ€è¦ç»´æŠ¤/ä¼ é€’å“ªäº›æ•°æ®ï¼š

### ä»»åŠ¡ä¿¡æ¯

```go
type MrTask struct {
	Id             int
	CreateTime     int64
	NReduce        int
	Type           TaskType
	Status         MrTaskStatus
	InputFileName  string
	InterFileNames []string
	OutputFileName string
}

type TaskType int

const (
	Map TaskType = iota
	Reduce
	NoMoreTasks
)

type MrTaskStatus int

const (
	Idle MrTaskStatus = iota
	InProgress
	Completed
)
```

ä¸å·¥ä½œåœ¨GFS / HDFSä¸Šçš„MapReduceç±»ä¼¼ï¼Œæˆ‘ä»¬çš„å®ç°ä¹Ÿæ˜¯åœ¨åŒä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿï¼ˆæœ¬åœ°æ–‡ä»¶ç³»ç»Ÿï¼‰ä¸Šçš„ã€‚ä»»åŠ¡ä¿¡æ¯é€šè¿‡RPCä¼ é€’ï¼Œè€Œä»»åŠ¡æ•°æ®åˆ™é€šè¿‡æ–‡ä»¶ä¼ è¾“ã€‚

ä¸‰ä¸ªFileName(s)å­—æ®µä¸­ï¼ŒMapä»»åŠ¡éœ€è¦è¯»å–`InputFileName`ï¼Œè¾“å‡º`InterFileNames`ï¼›Reduceä»»åŠ¡è¯»å–`InterFileNames`ï¼Œè¾“å‡º`OutputFileName`ã€‚

å¦å¤–ï¼Œå¼•å…¥`CreateTime`æ˜¯ä¸ºäº†ç¡®è®¤å”¯ä¸€çš„ä»»åŠ¡ï¼ˆæˆ–è€…è¯´ä»»åŠ¡çš„ä¸€æ¬¡æ‰§è¡Œï¼‰ã€‚å› ä¸ºä»»åŠ¡åœ¨è¶…æ—¶ï¼ˆlabä¸­è¦æ±‚çš„10ç§’ï¼‰åæ‰ä¼šé‡æ–°æŒ‡å®šworkeræ‰§è¡Œï¼Œæ‰€ä»¥`Id`å’Œ`CreateTime`ä¸€å®šå¯ä»¥ç¡®è®¤å”¯ä¸€çš„ä¸€æ¬¡ä»»åŠ¡æ‰§è¡Œã€‚

### Coordinator

```go
type Coordinator struct {
	inputFileNames []string
	nReduce        int              // number of reduce tasks
	workerTimeOut  time.Duration    // time to re-assign tasks, default 10s
	state          coordinatorState // coordinator state
	tasks          [][]MrTask       // mapreduce tasks, example: task[Map][taskId]
	taskCount      int              // the number of tasks which are not completed
	taskLock       sync.Mutex       // lock for update Task Status
	taskChannel    chan MrTask      // channel to assign Idle tasks
}

type coordinatorState int

const (
	creating coordinatorState = iota
	mapping
	reducing
	done
)
```

ä¸è®ºæ–‡ä¸­æåˆ°çš„ç±»ä¼¼ï¼Œmaster(coordinator)ç»´æŠ¤äº†å…³äºæ•´ä¸ªMapReduceç¨‹åºå’Œæ¯ä¸ªä»»åŠ¡çš„ä¿¡æ¯ã€‚taskChannelæœ¬èº«ç”±äºgo channelçš„ç‰¹æ€§ï¼Œå¯ä»¥ä¿è¯äº’æ–¥ï¼Œè€Œå…¶ä»–ä»»åŠ¡ä¿¡æ¯åˆ™éœ€è¦äº’æ–¥é”taskLockå®ç°äº’æ–¥è®¿é—®ã€‚

### RPCæ•°æ®

``` go
type GetTaskArgs struct {
	Nothing int
}
type GetTaskReply struct {
	Task MrTask
}

type ReportTaskArgs struct {
	Task MrTask
}
type ReportTaskReply struct {
	Nothing int
}
```

RPCåªæ¶‰åŠä¸¤ç§æƒ…å†µï¼š

- Workerå‘Coordinatorè¯·æ±‚ä»»åŠ¡
- Workerå‘Coordinatoræ±‡æŠ¥ä»»åŠ¡

äºŒè€…å‡åªéœ€è¦ä¼ é€’ä¸€æ¡ä»»åŠ¡ä¿¡æ¯ï¼Œä¸”æ— è®ºä»»åŠ¡æˆè´¥å‡ä¸Workeræ— å…³ï¼Œè€Œæ˜¯ç”±Coordinatoræ¥å†³å®šã€‚æ‰€ä»¥è¿™é‡Œä½¿ç”¨`Nothing`å ä½ï¼Œè€Œä¸éœ€è¦çœŸçš„æœ‰å‚æ•°/è¯·æ±‚ã€‚

## Workerè®¾è®¡

æ­£å¦‚å…¶åï¼Œworkeråªéœ€è¦workã€‚å®ƒæ‰€éœ€è¦åšçš„å°±æ˜¯è¯·æ±‚ä»»åŠ¡->æ‰§è¡Œä»»åŠ¡->æ±‡æŠ¥ä»»åŠ¡ï¼Œä¸æ–­å¾ªç¯ã€‚

```go
// main/mrworker.go calls this function.
func Worker(mapFunc func(string, string) []KeyValue,
	reduceFunc func(string, []string) string) {
	for {
		task := getTaskCall()
		if task.Type == Map {
			// read from input file
			file, err := os.Open(task.InputFileName)
			if err != nil {
				log.Fatalf("cannot open input file %v", task.InputFileName)
			}
			content, err := io.ReadAll(file)
			if err != nil {
				log.Fatalf("cannot read %v", task.InputFileName)
			}
			err = file.Close()
			if err != nil {
				log.Fatalf("cannot close %v: %v", task.InputFileName, err)
			}

			// run map function
			keyValues := mapFunc(task.InputFileName, string(content))

			// split intermediate data into R(or NReduce) pieces
			interDatas := make([][]KeyValue, 0)
			for i := 0; i < task.NReduce; i++ {
				interDatas = append(interDatas, make([]KeyValue, 0))
			}
			for _, kv := range keyValues {
				index := ihash(kv.Key) % task.NReduce
				interDatas[index] = append(interDatas[index], kv)
			}

			// serialize and write intermediate file
			for i := 0; i < task.NReduce; i++ {
				var buffer bytes.Buffer
				enc := gob.NewEncoder(&buffer)
				err := enc.Encode(interDatas[i])
				if err != nil {
					log.Fatal("encode error:", err)
				}
				interFileName := fmt.Sprintf("mr-map-%v-reduce-%v-%v", task.Id, i, task.CreateTime)
				file, err := os.Create(interFileName)
				if err != nil {
					log.Fatalf("cannot create %v", interFileName)
				}
				_, err = file.Write(buffer.Bytes())
				if err != nil {
					log.Fatalf("cannot write %v", interFileName)
				}
				err = file.Close()
				if err != nil {
					log.Fatalf("cannot close %v", interFileName)
				}
				task.InterFileNames = append(task.InterFileNames, interFileName)
			}
			task.Status = Completed

		} else if task.Type == Reduce {
			// read and deserialize intermedia data
			var interData []KeyValue
			interNum := len(task.InterFileNames)
			for i := 0; i < interNum; i++ {
				var buffer bytes.Buffer
				dec := gob.NewDecoder(&buffer)
				interFileName := task.InterFileNames[i]
				file, err := os.Open(interFileName)
				if err != nil {
					log.Fatalf("cannot open intermediate file %v", interFileName)
				}
				content, err := io.ReadAll(file)
				if err != nil {
					log.Fatalf("cannot read %v", interFileName)
				}
				err = file.Close()
				if err != nil {
					log.Fatalf("cannot close %v", interFileName)
				}
				buffer.Write(content)
				var data []KeyValue
				err = dec.Decode(&data)
				if err != nil {
					log.Fatal("decode error:", err)
				}
				interData = append(interData, data...)
			}
			// prepare (Key, list(Value)) for reduce function
			kvMap := make(map[string][]string)
			for _, kv := range interData {
				elem, ok := kvMap[kv.Key]
				if ok {
					kvMap[kv.Key] = append(elem, kv.Value)
				} else {
					kvMap[kv.Key] = []string{kv.Value}
				}
			}

			// run reduce function
			outputString := ""
			for key, values := range kvMap {
				outputString += fmt.Sprintf("%v %v\n", key, reduceFunc(key, values))
			}

			// write output file
			outputFileName := fmt.Sprintf("mr-out-%v-%v", task.Id, task.CreateTime)
			file, err := os.Create(outputFileName)
			if err != nil {
				log.Fatalf("cannot create %v", outputFileName)
			}
			_, err = file.WriteString(outputString)
			if err != nil {
				log.Fatalf("cannot write %v", outputFileName)
			}
			err = file.Close()
			if err != nil {
				log.Fatalf("cannot close %v", outputFileName)
			}
			task.OutputFileName = outputFileName
			task.Status = Completed

		} else if task.Type == NoMoreTasks {
			os.Exit(0)
		}

		// report Task
		ReportTaskCall(task)
	}
}
```

å€¼å¾—æ³¨æ„çš„æ˜¯ä¸­é—´æ–‡ä»¶/è¾“å‡ºæ–‡ä»¶çš„å‘½åï¼šäºŒè€…å‡è¿½åŠ äº†æ—¶é—´æˆ³ï¼Œç”¨äºé¿å…å†²çªã€‚è€Œæœ€ç»ˆæ˜¯å¦å°†ä¸­é—´æ–‡ä»¶ç”¨äºç”Ÿæˆreduceä»»åŠ¡/å°†è¾“å‡ºæ–‡ä»¶ç¡®è®¤ä¸ºæœ€ç»ˆç»“æœï¼ˆåˆ å»æ–‡ä»¶åçš„æ—¶é—´æˆ³ï¼‰ï¼Œéƒ½äº¤ç”±coordinatorå†³å®šã€‚

## Coordinatorè®¾è®¡

ç›¸è¾ƒäºé€»è¾‘éå¸¸ç®€å•çš„Workerï¼ŒCoordinatorçš„ä»»åŠ¡è¾ƒä¸ºå¤æ‚ã€‚éœ€è¦ç”Ÿæˆä»»åŠ¡ã€åˆ†é…ä»»åŠ¡ã€åˆ¤æ–­ä»»åŠ¡æ˜¯å¦æ­£å¸¸å®Œæˆç­‰ã€‚å…¶ä¸­é™¤äº†ç”Ÿæˆä»»åŠ¡çš„éƒ¨åˆ†ä»¥å¤–å‡éœ€è¦å¹¶å‘ã€‚

```mermaid
graph LR
	genmap((ç”Ÿæˆ map ä»»åŠ¡))-->map1(æ‰§è¡Œ map ä»»åŠ¡)-->genred((ç”Ÿæˆ reduce ä»»åŠ¡))-->red1(æ‰§è¡Œ reduce ä»»åŠ¡)-->fin((å®Œæˆ MapReduce))
	genmap-->map2(æ‰§è¡Œ map ä»»åŠ¡)-->genred
	genmap-->map3(æ‰§è¡Œ map ä»»åŠ¡)-->genred
	genred-->red2(æ‰§è¡Œ reduce ä»»åŠ¡)-->fin
	genred-->red3(æ‰§è¡Œ reduce ä»»åŠ¡)-->fin
```



### åˆ›å»ºCoordinator

```go
// create a Coordinator.
// main/mrcoordinator.go calls this function.
// NReduce is the number of reduce tasks to use.
func MakeCoordinator(files []string, nReduce int) *Coordinator {
	c := Coordinator{
		inputFileNames: files,
		nReduce:        nReduce,
		workerTimeOut:  time.Second * 10,
		state:          creating,
		tasks:          [][]MrTask{make([]MrTask, 0), make([]MrTask, 0)},
		taskLock:       sync.Mutex{},
		taskChannel:    make(chan MrTask, max_(len(files), nReduce)+1),
	}
	c.taskLock.Lock()
	c.generateMapTasks()
	c.taskLock.Unlock()
	c.server()
	return &c
}
```

åˆ›å»ºcoordinatorï¼Œç”Ÿæˆmapä»»åŠ¡ï¼Œè¿è¡ŒRPCæœåŠ¡ç«¯ã€‚

### ç”Ÿæˆ map ä»»åŠ¡

``` go
func (c *Coordinator) generateMapTasks() {
	taskNumber := len(c.inputFileNames)
	for i := 0; i < taskNumber; i++ {
		task := MrTask{
			Id:             i,
			CreateTime:     time.Now().Unix(),
			NReduce:        c.nReduce,
			Type:           Map,
			Status:         Idle,
			InputFileName:  c.inputFileNames[i],
			InterFileNames: make([]string, 0),
		}
		c.tasks[Map] = append(c.tasks[Map], task)
	}
	c.taskCount = taskNumber
	c.state = mapping
	for _, task := range c.tasks[Map] {
		c.taskChannel <- task
	}
}
```

### ç”Ÿæˆ reduce ä»»åŠ¡

``` go
func (c *Coordinator) generateReduceTasks() {
	mapTaskNumber := len(c.inputFileNames)
	reduceTaskNumber := c.nReduce

	for i := 0; i < reduceTaskNumber; i++ {
		task := MrTask{
			Id:             i,
			CreateTime:     time.Now().Unix(),
			NReduce:        c.nReduce,
			Type:           Reduce,
			Status:         Idle,
			InterFileNames: make([]string, 0),
		}
		c.tasks[Reduce] = append(c.tasks[Reduce], task)
	}

	// shuffle intermediate files
	for mapIndex := 0; mapIndex < mapTaskNumber; mapIndex++ {
		for reduceIndex := 0; reduceIndex < reduceTaskNumber; reduceIndex++ {
			c.tasks[Reduce][reduceIndex].InterFileNames =
				append(c.tasks[Reduce][reduceIndex].InterFileNames,
					c.tasks[Map][mapIndex].InterFileNames[reduceIndex])
		}
	}

	c.taskCount = reduceTaskNumber
	c.state = reducing
	for _, task := range c.tasks[Reduce] {
		c.taskChannel <- task
	}
}
```

### å¾—å‡ºè¾“å‡ºæ–‡ä»¶ & åˆ é™¤ä¸­é—´æ–‡ä»¶

```go
// CleanUp - remove intermedia files & rename output files
func (c *Coordinator) CleanUp() {
	for _, task := range c.tasks[Reduce] {
		deleteFiles(task.InterFileNames)
		renameFile(task.OutputFileName, fmt.Sprintf("mr-out-%v", task.Id))
	}
}
```



### å¤„ç† workerè¯·æ±‚

å¦‚ä¸Šæ–‡ï¼Œworkerä¼šåœ¨ä¸¤ç§æƒ…å†µä¸‹ä½¿ç”¨RPCå‘coordinatorå‘é€è¯·æ±‚ï¼š

- è·å–ä»»åŠ¡

    ```go
    func (c *Coordinator) GetTask(args *GetTaskArgs, reply *GetTaskReply) error {
    	_ = args
    	task := <-c.taskChannel
    	if task.Type != NoMoreTasks {
    		c.taskLock.Lock()
    		defer c.taskLock.Unlock()
    		c.tasks[task.Type][task.Id].Status = InProgress
    		go c.taskTimeOut(&c.tasks[task.Type][task.Id])
    	}
    	reply.Task = task
    	return nil
    }
    
    func (c *Coordinator) taskTimeOut(task *MrTask) {
        time.Sleep(c.workerTimeOut)
        c.taskLock.Lock()
        defer c.taskLock.Unlock()
        if task.Status != Completed {
            // worker time out, create a new task
            task.Status = Idle
            task.CreateTime = time.Now().Unix()
            c.taskChannel <- *task
        }
    }
    ```
    
    å½“workerè·å–ä»»åŠ¡æ—¶ï¼Œcoordinatorçš„ä»»åŠ¡åˆ—è¡¨ä¸­ï¼Œä¼šå°†è¿™æ¬¡ä»»åŠ¡æ ‡è®°ä¸º`InProgress`ã€‚åŒæ—¶ï¼Œåˆ›å»ºä¸€ä¸ª go routine ç”¨äºè®¡æ—¶ã€‚å¦‚æœ10ç§’åï¼Œè¿™æ¬¡ä»»åŠ¡è¿˜æ²¡æœ‰å®Œæˆï¼Œåˆ™è§†ä¸ºå¤±è´¥ã€‚è¿™æ—¶ä¼šä½¿ç”¨ä¸€ä¸ªæ–°çš„æ—¶é—´æˆ³æ¥åˆ›å»ºæ–°çš„ä»»åŠ¡ï¼Œå¹¶æ”¾å…¥ç­‰å¾…æ‰§è¡Œçš„channelä¸­ã€‚
    
- æ±‡æŠ¥ä»»åŠ¡

    ```go
    func (c *Coordinator) ReportTask(args *ReportTaskArgs, reply *ReportTaskReply) error {
    	_ = reply
    	taskId := args.Task.Id
    	taskType := args.Task.Type
    	c.taskLock.Lock()
    	defer c.taskLock.Unlock()
    	if c.tasks[taskType][taskId].CreateTime == args.Task.CreateTime {
    		// completed in time, take as valid report
    		c.tasks[taskType][taskId] = args.Task
    		c.taskCount--
    		if c.taskCount == 0 {
    			if c.state == mapping {
    				c.generateReduceTasks()
    				c.state = reducing
    			} else if c.state == reducing {
    				c.CleanUp()
    				c.state = done
    			}
    		}
    	} else {
    		// time out, invalid report
    		if args.Task.Type == Map {
    			deleteFiles(args.Task.InterFileNames)
    		} else {
    			deleteFiles([]string{args.Task.OutputFileName})
    		}
    	}
    	return nil
    }
    ```

    å¦‚æœæ±‡æŠ¥çš„ä»»åŠ¡ä¸coordinatorä¸­çš„æ—¶é—´æˆ³ä¸ç¬¦ï¼Œåˆ™è¡¨æ˜è¿™æ¬¡æ±‡æŠ¥çš„ä»»åŠ¡å·²ç»å› ä¸ºè¶…æ—¶ï¼Œè¢«å†æ¬¡åˆ†é…äº†ã€‚

    å¦‚æœæ—¶é—´æˆ³ç›¸ç¬¦ï¼Œåˆ™è¯æ˜æ˜¯ä¸€æ¬¡æˆåŠŸçš„ä»»åŠ¡æ‰§è¡Œã€‚è¿™æ—¶coordinatorä½¿ç”¨æ±‡æŠ¥çš„ä»»åŠ¡ä¿¡æ¯æ›¿æ¢è‡ªèº«ä¿å­˜çš„ä»»åŠ¡ä¿¡æ¯ã€‚

    å½“æ‰€æœ‰ä»»åŠ¡éƒ½è¢«æˆåŠŸæ‰§è¡Œåï¼ˆ`taskCount`å‡ä¸º0ï¼‰ï¼Œåˆ™coordinatorä¼šè½¬å…¥ä¸‹ä¸€ä¸ªå·¥ä½œé˜¶æ®µï¼šä»mappingåˆ°reducingï¼Œæˆ–è€…ä»reducingåˆ°doneã€‚

# æµ‹è¯•ç»“æœ

```bash
$ bash test-mr.sh
*** Starting wc test.
--- wc test: PASS
*** Starting indexer test.
--- indexer test: PASS
*** Starting map parallelism test.
--- map parallelism test: PASS
*** Starting reduce parallelism test.
--- reduce parallelism test: PASS
*** Starting job count test.
unexpected EOF
unexpected EOF
2024/02/20 21:04:09 Get Task failed!
2024/02/20 21:04:09 Get Task failed!
--- job count test: PASS
*** Starting early exit test.
--- early exit test: PASS
*** Starting crash test.
unexpected EOF
unexpected EOF
unexpected EOF
2024/02/20 21:04:37 Get Task failed!
2024/02/20 21:04:37 Get Task failed!
2024/02/20 21:04:37 Get Task failed!
--- crash test: PASS
*** PASSED ALL TESTS
```

## å¼‚å¸¸åˆ†æ

åˆ°è¿™é‡Œå·²ç»å®Œæˆäº†æ‰€æœ‰çš„testï¼Œä½†æ˜¯å…¶ä¸­å‡ºç°çš„ä¸€äº›å¼‚å¸¸æœ‰äº›ç¢çœ¼ã€‚

unexpected EOF å’Œ Get Task failed! ä»…æˆå¯¹å‡ºç°äºcoordinatoræ—©äºworkerç»“æŸçš„æƒ…å†µï¼šcoordinatorå·²ç»å®ŒæˆMapReduceä»»åŠ¡ï¼Œå…³é—­RPCæœåŠ¡ç«¯ï¼›è€Œworkerä»ç„¶é€šè¿‡RPCå®¢æˆ·ç«¯å°è¯•è·å–ä»»åŠ¡ï¼Œå¯¼è‡´å¼‚å¸¸é€€å‡ºï¼ˆlog.Fatal(xxx)ï¼‰ã€‚

äº‹å®ä¸Šè¿™äº›å¼‚å¸¸å‡å‘ç”Ÿåœ¨MapReduceä»»åŠ¡ç»“æŸåï¼Œå¹¶ä¸ä¼šå½±å“æµ‹è¯•ç»“æœï¼Œä½†æ˜¯å¯¹äºä»£ç çš„ç²¾ç¥æ´ç™–ä¿ƒä½¿æˆ‘å°è¯•è§£å†³è¿™äº›å¼‚å¸¸ï¼š

### job count test

å…¶ä¸­ï¼Œjob count testå‡ºç°è¿™ä¸€é—®é¢˜æ˜¯å› ä¸º`test-mr.sh`ä¸­å°‘äº†ä¸€ä¸ª`&`

```bash
maybe_quiet $TIMEOUT ../mrworker ../../mrapps/jobcount.so &
maybe_quiet $TIMEOUT ../mrworker ../../mrapps/jobcount.so
maybe_quiet $TIMEOUT ../mrworker ../../mrapps/jobcount.so &
maybe_quiet $TIMEOUT ../mrworker ../../mrapps/jobcount.so
```

ç”±äºç¬¬äºŒä¸ªworkerä¸æ˜¯ä½¿ç”¨subshellåå°è¿è¡Œï¼Œå¯¼è‡´å‰ä¸¤ä¸ªworkerç»“æŸåæ‰ä¼šå¯åŠ¨åä¸¤ä¸ªworkerã€‚è€Œå‰ä¸¤ä¸ªworkerä¸coordinatorå‡ ä¹åŒæ—¶ç»“æŸï¼ˆworkeråœ¨æ‰§è¡Œå®Œæœ€åä¸€ä¸ªä»»åŠ¡åï¼Œæ”¶åˆ°`NoMoreTasks`ç»“æŸï¼›coordinatoråœ¨`src/main/mrcoordinator.go`å‘ç°ä»»åŠ¡ç»“æŸåè¢«ç»“æŸï¼‰ã€‚

```go
func main() {
	if len(os.Args) < 2 {
		fmt.Fprintf(os.Stderr, "Usage: mrcoordinator inputfiles...\n")
		os.Exit(1)
	}

	m := mr.MakeCoordinator(os.Args[1:], 10)
	for m.Done() == false {
		time.Sleep(time.Second)
	}

	time.Sleep(time.Second)
}
```

æ‰€ä»¥åä¸¤ä¸ªworkerè·å–ä»»åŠ¡å¤±è´¥ã€‚

è§£å†³æ–¹æ¡ˆï¼šåœ¨ç¬¬äºŒä¸ªmrworkeråæ·»åŠ `&`

### crash test

crash test ä¸­çš„å¼‚å¸¸æˆå› ç±»ä¼¼ï¼Œä½†å¹¶ä¸å®Œå…¨æ˜¯æµ‹è¯•è„šæœ¬çš„é—®é¢˜ï¼š

```bash
rm -f mr-done
((maybe_quiet $TIMEOUT2 ../mrcoordinator ../pg*txt); touch mr-done ) &
sleep 1

# start multiple workers
maybe_quiet $TIMEOUT2 ../mrworker ../../mrapps/crash.so &

# mimic rpc.go's coordinatorSock()
SOCKNAME=/var/tmp/5840-mr-`id -u`

( while [ -e $SOCKNAME -a ! -f mr-done ]
  do
    maybe_quiet $TIMEOUT2 ../mrworker ../../mrapps/crash.so
    sleep 1
  done ) &

( while [ -e $SOCKNAME -a ! -f mr-done ]
  do
    maybe_quiet $TIMEOUT2 ../mrworker ../../mrapps/crash.so
    sleep 1
  done ) &

while [ -e $SOCKNAME -a ! -f mr-done ]
do
  maybe_quiet $TIMEOUT2 ../mrworker ../../mrapps/crash.so
  sleep 1
done

```

åœ¨è¿™ä¸ªtestä¸­ï¼Œä½¿ç”¨ä¸‰ä¸ªwhileæ¥å¯åŠ¨workerï¼šå½“workerç»“æŸ**ä¸€ç§’**åï¼Œåªè¦coordinatoræ²¡æœ‰ç»“æŸï¼Œå°±å†æ¬¡å¯åŠ¨workerã€‚

ä½†æ˜¯`src/main/mrcoordinator.go`ä¸­ï¼Œè°ƒç”¨`m.Done()`åsleepä¸€ç§’ï¼Œå½“è¿”å›å€¼ä¸ºtrueæ—¶å†sleepä¸€ç§’ï¼šå¿½ç•¥æ‰§è¡Œæ—¶é—´ï¼Œå½“`coordinator.State`è¢«è®¾ä¸º`done`åçš„**1-2ç§’**ï¼Œcoordinatorè¢«ç»“æŸã€‚

è€Œcoordinatorçš„å®ç°ä¸­ï¼Œåªç»“æŸäº†è¿è¡Œå®Œæœ€åä¸€ä¸ªä»»åŠ¡æ—¶è¢«é˜»å¡çš„workerï¼Œå¹¶æ²¡æœ‰è€ƒè™‘åˆ°è¿™ä¹‹åçš„workerã€‚

```go
c.CleanUp()
c.state = done

// send NoMoreTasks to pending workers
for fin := false; !fin; {
    select {
    case <-c.taskChannel:
        fin = true
    default:
        c.taskChannel <- MrTask{Type: NoMoreTasks}
    }
}
// send to the worker that reported the last task
c.taskChannel <- MrTask{Type: NoMoreTasks}
```



è¿™é‡Œæˆ‘çš„å®ç°æ€è·¯ä¸æµ‹è¯•ä»£ç æš—å«çš„å‡ºé¢˜äººçš„æ€è·¯ä¸åŒï¼Œæˆ‘ä¸ªäººè®¤ä¸ºä¸¤ç§æ€è·¯åº”å½“éƒ½æ˜¯æ­£ç¡®çš„ï¼šæˆ‘çš„æ€è·¯å€¾å‘äºåœ¨workeræ­£å¸¸ç»“æŸåä¸ä¼šäº§ç”Ÿæ–°çš„workerï¼›è€Œå‡ºé¢˜äººä¼¼ä¹è®¤ä¸ºworkerä¸ä¼šä¸»åŠ¨ç»“æŸï¼Œåªè¦ç»“æŸå°±åº”å½“æ˜¯crashã€‚

è§£å†³æ–¹æ¡ˆæœ‰ä¸¤ç§ï¼š

1. å°†æµ‹è¯•è„šæœ¬ä¸­çš„`sleep 1`æ”¹ä¸º`sleep 2`
2. ä½¿coordinatoræŒç»­å‘`taskChannel`è¾“å…¥`MrTask{Type: NoMoreTasks}`ï¼Œä»¥ç»“æŸåç»­æ‰€æœ‰çš„workerã€‚ï¼ˆä¸Šä¸€ä¸ªé—®é¢˜ä¹Ÿå¯ä»¥è¢«è¿™ä¸€æ–¹æ¡ˆè§£å†³ï¼Œä½†æ˜¯testçš„é€»è¾‘ç¡®å®æœ‰é—®é¢˜ï¼Œæ‰€ä»¥ä»ç„¶åº”å½“æŒ‰ç…§ä¸Šæ–‡ä¿®æ”¹æµ‹è¯•ä»£ç ï¼‰
    ```go
    c.CleanUp()
    
    // send NoMoreTasks to workers
    go func() {
        for {
            c.taskChannel <- MrTask{Type: NoMoreTasks}
        }
    }()
    
    c.state = done
    ```

ä¿®æ”¹åæµ‹è¯•ç»“æœå®Œå…¨æ­£å¸¸ï¼ˆå¯ç”¨äº†goçš„race detectorï¼‰ï¼š

```bash
$ bash test-mr.sh
*** Starting wc test.
--- wc test: PASS
*** Starting indexer test.
--- indexer test: PASS
*** Starting map parallelism test.
--- map parallelism test: PASS
*** Starting reduce parallelism test.
--- reduce parallelism test: PASS
*** Starting job count test.
--- job count test: PASS
*** Starting early exit test.
--- early exit test: PASS
*** Starting crash test.
--- crash test: PASS
*** PASSED ALL TESTS
```

